# Azure OpenAI Configuration
LLM_PROVIDER=azure_openai

OUTPUT_PATH=output

# Azure OpenAI credentials
AZURE_API_KEY=EzqbdX8l2m0PzedkWSxkjESB5wGGDseac0Aq8SmfthOIqZ6jweNQJQQJ99BCACYeBjFXJ3w3AAABACOG5ZKu
AZURE_API_BASE=https://qmig-open-ai.openai.azure.com/
AZURE_API_VERSION=2023-08-01-preview
AZURE_MODEL =gpt-4o

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-4o
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=4096

# Anthropic Configuration
ANTHROPIC_API_KEY=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
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_MAX_TOKENS=4096

# Groq Configuration
GROQ_API_KEY=your-groq-api-key
GROQ_MODEL=llama3-70b-8192
GROQ_TEMPERATURE=0.7
GROQ_MAX_TOKENS=4096

# Google Gemini Configuration
GEMINI_API_KEY=AIzaSyCeBF3bPaNGaFNzJgLIpOsSeqG8S2FRmNk
GEMINI_MODEL=gemini-2.0-flash
GEMINI_TEMPERATURE=0.7
GEMINI_MAX_TOKENS=4096

# Ollama Configuration (for local models)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3
OLLAMA_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=4096
